---
title: "Mall package demo"
format: html
---

This is a short demo of the package R version of the `mall` package (a Python version also exists).  `mall` is designed to give data scientists an easy workflow to perform classic NLP inference using both local and remote vendor LLMs.

For local LLMs to work, `ollama` must be installed locally or on the same server and the `ollamar` package must be used to interact with `ollama`.  For remote LLMs, the `ellmer` package is used.  Note that the current CRAN version of `mall` only supports local LLM use, but the dev version supports both.  To install the dev version use `pak::pak("mlverse/mall/r")`. 


```{r warning=FALSE, message=FALSE}
library(mall)
library(dplyr)
library(ellmer)
library(ollamar)

# use simple reviews dataset
data("reviews")
```

## Start with local models using `ollamar`

```{r}
# check models
ollamar::list_models()
```

### Use locally installed Gemma model

```{r}
# use gemma
mall::llm_use(backend = "ollama", model = "gemma")
```


### Comment sentiment

```{r}
(reviews <- reviews |> 
  mall::llm_sentiment(review))
```

### Comment summary

```{r}
(reviews <- reviews |> 
  mall::llm_summarize(review, max_words = 5))
```

### Comment classification

```{r}
(reviews <- reviews |> 
  mall::llm_classify(review, labels = c("TV related", "Non-TV related")))
```

### Extract entities

```{r}
(reviews <- reviews |> 
  mall::llm_extract(review, labels = "product"))
```

### Verify

```{r}
(reviews <- reviews |> 
  mall::llm_verify(review, what = "Is this a statement about a TV?"))
```

### Translate

```{r}
(reviews <- reviews |> 
  mall::llm_translate(review, language = "Japanese"))
```

### Custom prompt

```{r}
my_prompt <- paste(
  "Answer a question.",
  "Return only the answer, no explanation",
  "Acceptable answers are 'yes', 'no'",
  "Answer this about the following text, is it about a computer?:"
)

(reviews <- reviews |> 
  mall::llm_custom(review, my_prompt))
```

## Move to remote models using `ellmer`

```{r}
# this only currently works with the DEV version of mall
# pak::pak("mlverse/mall/r")

# set chat session with Claude
chat <- ellmer::chat_claude(
  base_url = Sys.getenv("ANTHROPIC_BASE_URL")
)

# tell mall to use this chat session as its backend
mall::llm_use(backend = chat)
```

### Comment sentiment

```{r}
(reviews <- reviews |> 
  mall::llm_sentiment(review))
```

### Comment summary

```{r}
(reviews <- reviews |> 
  mall::llm_summarize(review, max_words = 5))
```

### Comment classification

```{r}
(reviews <- reviews |> 
  mall::llm_classify(review, labels = c("TV related", "Non-TV related")))
```

### Extract entities

```{r}
(reviews <- reviews |> 
  mall::llm_extract(review, labels = "product"))
```

### Verify

```{r}
(reviews <- reviews |> 
  mall::llm_verify(review, what = "Is this a statement about a TV?"))
```

### Translate

```{r}
(reviews <- reviews |> 
  mall::llm_translate(review, language = "Japanese"))
```

### Custom prompt

```{r}
my_prompt <- paste(
  "Answer a question.",
  "Return only the answer, no explanation",
  "Acceptable answers are 'yes', 'no'",
  "Answer this about the following text, is it about a computer?:"
)

(reviews <- reviews |> 
  mall::llm_custom(review, my_prompt))
```